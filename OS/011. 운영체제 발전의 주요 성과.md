# 운영체제 발전 과정에서 이뤄진 주요 성과들

    1. 프로세스 개념 등장
    2. 메모리 관리 진전
    3. 정보보호 및 보안
    4. 스케줄링 및 자원관리 발전

## 1. 프로세스에 대한 개념이 등장

### 프로세스란?

> 프로세스(process)는 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램을 말한다. 종종 스케줄링의 대상이 되는 작업(task)이라는 용어와 거의 같은 의미로 쓰인다. <프로세스>, 위키백과.

즉, 우리가 실생활에서 윈도우 같은 운영체제를 통하여하나의 프로그램을 실행하면, 그것이 바로 하나의 프로세스임.

프로세스라는 용어가 사용되기 이전에는, 1960년대 "Job"이라는 용어가 Multics라는 운영체제가 설계될 때 처음 사용되었다. 프로세스는 이후 Job에 여러 다른 개념들이 추가적으로 들어간 개념으로 보면 좋다.

* 프로세스는 네 가지 측면으로 정의해볼 수 있다. 

  * 컴퓨터에서 실행중인 프로그램

  * 컴퓨터에서 실행중인 프로그램의 한 인스턴스(메모리, 처리기를 점유하는 object로서)

  * 처리기에 할당되어 수행될 수 있는 개체 (처리기가 실행할 수 있는 어떤 것)

  * "**쓰레드**"라는 개념이 등장하기 이전, 하나의 프로세스 내에 있는 쓰레드(프로세스를 실행하는 주체)도 프로세스라고 불렸다. 
    ** 프로세스가 생겨난 초기에는 쓰레드라는 개념이 없었고 그냥 오늘날의 쓰레드가 프로세스로 받아들여졌었다. 쓰레드라는 용어가 생기고 나서 프로그램 내에서 병렬적으로 수행되는 주체를 쓰레드라고 부르기 시작한 것이다.
    
    > 웹 브라우저(프로그램이자 프로세스)를 띄우는 상황을 예로 들 수 있다. 브라우저를 실행시키면, 브라우저에서는 여러 실행 단위들이 병렬적으로 실행되고 있는 것이다. 그 이유로 어떤 웹 사이트에 접속하게 되면, 준비가 완료된 부분을 먼저 볼 수 있게 되며, 이는 기다리는 사용자의 답답함을 어느 정도 해소시킨다 볼 수 있다. 이 과정에서 **프로세스 내에서 병렬적으로 수행되고 있는 실행 단위들**이 바로 **쓰레드**이다. 

* 프로세스라는 용어가 생겨나면서, '프로세스를 **종료**시킨다'(kill)는 용어 역시 생겨났다. 이는 프로세스가 비정상적 경로로 명령어에 접근할 때 운영체제가 그 프로세스의 실행을 종료시킨다는 것으로 이해해볼 수 있다.

  > 예를 들어, 서로 다른 A, B프로세스가 있다고 가정한다.
  > 
  > A 프로세스 내에서 프로그램이 실행될 때 A 프로세스 내에 있는 메모리에 엑세스할텐데, 만약 또 다른 B프로세스가 실행중일 때, A 프로세스에서 B 프로세스의 메모리로 접근하는 일이 일어난다면, 보안에 문제가 생긴다. 또한 A프로세스의 오동작으로 인하여 B프로세스도 영향을 받게 됨. 이런 것들은 B번 프로세스 입장에서 자기는 문제가 없지만 다른 프로세스가 오동작하면 두 프로세스 모두 문제에 처하게 될 것이다. 따라서 **프로세스는 자기 자신의 메모리에서 벗어나서 다른 영역을 접근하는 것을 금지**시킨다. 그럼 어떠한 방식으로 일어나냐? 앞서 언급하였던 일들이 일어나려고 할 때, 운영체제는 즉시 그 프로세스를 ‘없애’버린다.

* 프로세스의 탄생 배경

운영체제에서는 타이밍, 동기화문제 존재하였고, 이 두 가지 문제점으로 인해 프로세스가 탄생하였다.

  1.타이밍
- 시분할 시스템 운영체제의 등장으로, 시간을 일정하게 쪼개어 번갈아 실행되어야 하는 여러 실행 주체(인스턴스)라는 개념을 만들어야 했음. 그것이 프로세스라는 개념이 탄생한 동기 중 하나

2. 동기화문제
- 두개의 실행 주체가 동시에 실행되고 있을 때, 어떤 메모리/디스크/네트워크 등 컴퓨터 자원을 서로 공유하고 있는 상황에서, 이 자원을 한 실행 주체가 읽고 있을 때, 다른 주체가 쓴다거나 하는 상황이 일어난다면, 어떤 순서대로 작업이 이뤄져야 하는지가 중요함. 예를 들면 수정하고 있는 동안에 읽게 되면 곤란함... 그런 동기화 문제를 해결해야 했음. 동기화문제를 해결하기 위해 공유된 자원에 접근하는 주체들이 무엇인가에 대한 개념이 필요했음. 그 개념으로 프로세스라는 개념이 탄생하게 됨.

프로세스 별로 시간을 쪼개어 실시간으로 데이터를 처리하게 되면(시분할 시스템), 응답 시간이 빨라짐. 시분할 시스템에서는 빠른 응답시간을 제공해주는 것이 중요한 문제. 유저가 키보드를 타이핑하면, 즉시 컴퓨터가 반응을 해주어야 함. 그렇게 하기 위해서는 프로세스라는 개념이 필요했음..

그렇게 여러 개의 프로세스가 실행을 하다 보니, 에러가 발생하면 그 에러의 원인이 어떤 프로세스에 있는지 파악하기가 어려움. 이러한 에러의 주요 원인으로는
i. 부적절한 동기화(서로 공유하고 있는 자원을 사용할 때에는 프로세스들이 순서를 잘 지켜 사용해야 하고, 변경 도중에 읽으면 안되는 등 규칙들을 지켜야 하는데, 이러한 동기화가 잘 되지 않을 때- 부적절한 동기화가 발생할 때 오류가 생김)
ii. 동기화를 시키기 위해 우리가 어떤 것을 이용하냐 하면, lock같은 것을 이용하여 상호배제를 함. 상호배제란 프로세스A가 공유자원 P를 접근할 때에는 B 또는 C프로세스 같은 다른 프로세스들이 공유자원 P로 접근하지 못하도록 하는 것. 공유자원에 대해 상호 배제가 잘 이뤄져야 하는데, 이것들이 잘 안되는 경우 에러가 일어남.
iii. 비결정적인 프로그램 연산 : 어떤 동일한 메모리를 공유하고 있을 때, 다른 프로그램이 갑자기 그 공유메모리에 엉뚱한 값을 써서(write) 한 프로그램에 영향을 받으면, 그 프로그램은 실행할 때마다 어떻게 진행될지 잘 모를 것. 그렇기 때문에 비결정적임...
iv. 공유자원을 처리할 때(상호배제를 하기 위해 상호배제하는 메커니즘을 잘 이용해야 함-lock), lock을 걸고 풀고 함. 그럴 때, 프로그램들이 서로 lock을 물고 있는 상태. 그것이 바로 교착상태임. 이 교착상태(deadlock)이 일어나면 더 이상 진행이 되지 않고 오류가 생김

* 프로세스의 구성 요소

   - 메모리에 올라온 수행 가능한 프로그램(하나의 프로그램은 곧 프로세스)
   - 데이터(프로그램이 실행되다 보면, 데이터를 필요로 하는 때가 있다.)
   - 프로그램 수행 문맥
     * 한 프로그램이 실행될 때, 시분할 시스템에 의해 다른 프로그램이 실행될 수 있다. 다른 프로그램이 실행되다가 다시 그 프로그램으로 돌아왔을 때, 실행이 중단되었던 지점부터 다시 실행해야 할 것이다. 이 때, 중단되지 않고 끝까지 프로그램이 실행되는 과정과 중간에 끊겼다가 다시 실행되는 그 과정은 그 실행결과가 서로 같아야 할 것이다.(인터럽트 참고). 중단되었던 프로그램이 다시 실행될 때, 원래 상태를 유지하기 위해서는 그 프로그램의 여러 가지 상태정보들을 가지고 있어야 하는데, 이 상태 정보들이 바로 프로그램의 수행 문맥이다.

    process state(프로세스 상태 정보)란?
    
    프로세스를 감독하고 제어하기 위한 내부적인 데이터로, 수행 문맥을 이용해서 프로세스의 주소 공간을 서로서로 분리하는 데 사용한다. 
    예를 들어, 프로세스 A와 B가 있다고 하면, 각각의 프로세스는 프로그램, 데이터 그리고 문맥으로 하나의 프로세스를 이룬다.
    둘 중 하나의 프로세스가 실행될 때, 그 프로세스가 어떻게 실행되고 있는가에 대한 정보들이 처리기 내의 여러 레지스터들에 저장된다. 
    
    이러한 레지스터들로는
    
    process index : 몇 번 프로세스가 실행중인지 알려주는 레지스터
    PC : Program Counter
    base : base register에 저장된 주소는 바로 프로세스의 시작 주소
    limit: 프로세스 메모리의 크기
    
    등이 있다.

* **문맥 교환(Context Switching)**
* 
만약 어떤 프로세스(프로그램)가 실행이 되다가, 할당된 시간이 끝나면 프로세스의 수행이 중단되고 다른 프로세스가 실행되는 과정을 거친다. 이것을 바로 **문맥 교환**(context switch)이라고 함. 

> 프로세스 A에서 문맥 교환이 일어난다면, A는 실행을 멈추고 B가 실행될 것임. 그리고 B프로세스가 실행되고 타임 슬롯이 끝나 중단되고 A프로세스가 멈춘 지점부터 다시 실행되려고 할 때(문맥교환), 이 레지스터의 값은 바뀌어있을 것이다. 왜냐하면 B프로세스가 실행되고 있을 때, B가 처리기를 이용하여 실행됨에 따라 처리기 내부의 레지스터 값들은 바뀌어 있었을 것이기 때문이다. 
> 
> 만약 이러한 상태로 문맥교환 없이 레지스터 값들이 그대로인 상태에서 A프로세스가 다시 실행된다면, 그 때 A의 0실행 결과는 A가 중단 없이 실행된 결과와는 다를 것이다. 그렇기 때문에, A프로그램 실행 당시 처리기에 들어있던 레지스터의 정보들을 다른 곳에 저장했다가 문맥 교환이 일어났을 때 복구하는 과정이 필요하다. 프로그램 실행 중 프로세스 내의 context라는 메모리 공간에 그 프로세스의 상태 정보(당시 cpu의 레지스터의 값들)을 잘 두었다가, 다시 문맥 교환이 일어나면 프로그램에 저장해 두었던 값들을 레지스터에 복구한 다음에 이어서 실행해야 프로세스의 연속된 동작이 보장된다.

<br/>

## 2. 메모리 관리에 대한 진전

* **저장장치 관리의 주요 책무 - 가상메모리를 통하여**

  * 프로세스 분리
  > 가상메모리 사용으로 여러 프로세스들이 메모리에서 프로세스 별로 분리가 되는 효과가 있다. 디스크 중 메모리처럼 사용하는 일부 영역을 **스왑**이라고 하며, 스왑과 메인메모리를 합한 메모리가 컴퓨터의 전체 메모리가 된다. 각 프로세스에는 전부 0번지부터 시작하는 가상 주소가 지정되고, 그 가상 주소가 물리 주소로 바뀌어 프로세스가 실행된다. 이렇게 되면, 하나의 프로세스에서 다른 프로세스의 메모리로 접근할 수 없다. 왜냐하면 프로세스 내에서의 주소는 가상주소로 접근하며, 가상 주소라는 것은 특정 프로세스 내에서의 접근 수단이기 때문이다. 따라서 프로세스가 불법적인 가상주소로 접근한다면(100번지까지 있는데 105번으로 접근, -5번으로 접근하는 등), 운영체제가 그 프로세스를 강제로 종료시키게 된다. 

  * 자동 할당 및 관리
  > 물리 메모리(메인 메모리)나 디스크에 있는 스왑메모리를 관리해야 하는데, 만약 **프로세스 전체를 연속적으로 메모리에 할당을 하게 되면, 자원의 효율적 관리가 어렵다.** 따라서 메인메모리, 디스크 등을 전부 블록 단위로 나누어 페이지들을 할당하는 식으로 관리를 하는 것이다. 운영체제는 프로그램을 블록 단위로 관리하기에 메모리가 효율적으로 사용되고, 운영체제가 가상주소와 물리적 주소와 서로 맵핑(디스크에 있는 쪼개진 유저프로그램의 물리주소를 정해주는 일인 맵핑은 운영체제의 역할)을 하기 때문에 이것들이 메인메모리에서 공간이 프로세스별로 연속될 필요가 없는 것이다.

  * 모듈식 프로그래밍 지원
  > 프로그래머는 프로그램 모듈(전체가 아닌 일부분)을 메모리에 올렸다 내렸다 할 수 있어야 하는데. 운영체제가 가상메모리를 통해 이것을 가능하게 해준다.
  
  * 보호 및 접근 제어
  > 프로세스를 분리한다는 것은 **메모리를 배타적으로 사용**한다는 것이다. 어떤 특정 메모리 공간을 여러 프로세스가 같이(동시 x) 한 메모리를 사용할 수는 있다. 이것을 공유메모리라고 한다. 하지만 두 개 이상의 프로세스가 같은 공간을 동시에 사용할 수는 없기 때문에, 그 메모리를 공유하고 있을 때에 문제가 없도록 하기 위해서는 한 프로세스가 변경하고 있는 도중에는 다른 프로세스가 그 메모리로 접근하면 안되고 끝날 때까지 기다리도록 해야 할 것이다. 이러한 식으로 프로세스들이 메모리를 배타적으로 사용하도록 함으로써 메모리를 보호하거나 접근을 제어할 수 있도록 운영체제가 그 기능을 수행한다.
  
  * 장기 저장

* **가상 메모리 개념의 등장**

![가상메모리](https://user-images.githubusercontent.com/101035437/187317572-95baea81-76b9-4966-a75f-65a17c444933.png)

  > 프로세스는 **물리적으로**는 **연속적인 하나의 프로세스로 간주되지 않고, 적절한 단위(보통 4KB)로 나뉜다.** 이 하나의 단위를 **페이지(Page) 또는 블록(Block)**이라고 부른다. 디스크에 저장되어 있는, 페이지로 나눈 단위가 실행되도록 하기 위해서는 그 페이지를 **메인메모리에 적재**해야 한다. 이 때 메인메모리를 잘 활용하기 위해서 메모리에 있는 공간들 중 임의의 위치에 분리하여 적재하게 된다.
  > 
  > 그 결과, 그림과 같이, 메인메모리에 프로그램들이 **물리적으로는 흩어져**있게 된다. 그러나 **가상메모리**를 이용하면, **논리적으로는 각각의 프로세스는 연속된 메모리로서 관리**할 수 있게 된다. 
  > 
  > 이와 관련된 개념이 논리주소와 물리주소이다. 
  > 
  > * **논리주소** : 가상메모리에서 이용. 프로세스의 관점에서 사용하는 주소이며, 운영체제가 제공하는 가상 주소 공간에 대한 주소이다.(<논리주소>, 위키백과)
  > 
  > * **물리주소** : 컴퓨터의 메인 메모리를 접근할 때 사용되는 주소이며, 이 주소는 기억 장치의 주소 레지스터에 적재된다.(<실주소>, 위키백과)
  > 
  > 처리기를 통하여 가상주소로 접근하게 되면, 메모리 관리 유닛에서 가상메모리주소지정 매커니즘을 통해 가상주소를 물리적주소로 변환해주게 된다.
  > 

* **가상메모리 기법의 효과**

  * **가상메모리 기법은 [메모리 계층구조](https://github.com/kmkim2689/CS/blob/main/OS/005.%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EA%B3%84%EC%B8%B5%20%EA%B5%AC%EC%A1%B0.md)에 따라 더 효율적으로 메모리를 사용**할 수 있도록 한다. 메인메모리에 있는 각 공간은 디스크보다 훨씬 작다. 한 프로그램을 실행시키기 위해서 한 프로그램이 통째로 주기억장치에 적재된다면, 더 많은 프로그램을 실행시킬 여지가 줄어들게 된다. 따라서 메모리의 일부는 물리메모리에 있고, 또 메모리의 일부는 물리메모리에 없고 디스크에 그냥 유지하도록 하여 메모리를 효율적으로 사용할 수 있도록 하는 것이다. 결국 **가상메모리로 가리킬 수 있는 메모리는 전체적으로 보면 실제 램에 있는 물리적 메모리와 디스크에 있는 메모리를 합친 것**이라 볼 수 있다.

-메모리는 여러개의 프로세스가 공유할 수 있음.


- 응용프로그램은 종료가 되었을 때에도 데이터가 오랫동안 유지될 수 있도록 해야함. 필요한 내용은 전원이 꺼져도 데이터가 유지되는 디스크와 같은 저장장치를 이용하여 데이터가 계속 유지되도록 하는 기능을 운영체제가 제공해야 함.

<br/>

## 3. 정보보호 및 보안

운영체제가 적절히 관리되도록 여러 보안 기법들이 적용되었다.

* 보안을 하는 이유

  - **가용성** : 시스템이 중지되지 않도록(누군가가 침입하여 시스템이 망가지지 않도록) 
  - **기밀성** : 권한이 있는 사람만 데이터를 읽을 수 있도록 해야한다. 데이터 내에서 권한 정보를 부여했다가 권한이 없는 사용자가 데이터를 읽는 행위를 못하도록 하기 위해서 보안 기법이 필요하다. 
    > 예시) **암호화**와 같이 강제로 디스크를 물리적으로 떼서 다른 컴퓨터에서 실행한다고 해도 생각대로 데이터를 읽을 수 없도록 하는 기법

  - **데이터 무결성** : 데이터가 불법적으로 수정되지 못하도록 보호하기 위해 보안 기법이 필요하다.
  - **신빙성** : 위의 세 가지 요소들을 위해 사용자의 아이디/비밀번호 등으로 신원을 검증하고, 각각의 데이터 권한 정보를 유지하여 권한 없는 사람이 데이터 접근 못하도록 하는 매커니즘들이 필요한데, 이 기법들 역시 운영체제가 제공한다.

<br/>

## 4. 스케줄링, 자원관리 발전

> 운영체제에서 프로세스들이 동시에 실행될 때, 프로세스 실행 순서를 어떻게 결정하는가에 관한 문제이다. 프로세스가 실행되는 어떤 순서를 프로세스 스케줄링이라고 하는데, 프로세스 스케줄링은 여러 정책에 따라 이뤄진다. 

* 스케줄링 정책을 결정하는데 중요한 요소들

  - **공정성** : 각각의 프로세스가 특정 자원을 서로 빨리 점유하려고 경쟁할 때(디스크, 메모리, 입출력 장치 등), 여러 프로세스에 공정하게 시스템 자원을 분배해야 한다. 

  - **반응시간 차등화**: 어떤 상황에서는 빠르게 반응해야 할 것이고, 다른 상황에는 느리게 반응해도 될 것이다. 이러한 사항을 감안하여 반응시간을 차등화할 수 있어야 한다.

    > 반응시간 : 어떤 프로세스가 실행되었다가 유저에게 결과를 알려주는 시간/서비스를 요청했다가 서비스가 끝나는 시간

  - **효율성** : 주어진 시간에 최대한 많은 양을 실행하고, 최대한 많은 수의 사용자들을 허용해야 해야 컴퓨터가 효율적으로 동작할 수 있다.

<br/>

## 출처 및 참고

- 학교 수업 내용
- William Stallings 저(전광일 등 역), 운영체제-내부구조 및 설계원리 제8판, 프로텍미디어.
