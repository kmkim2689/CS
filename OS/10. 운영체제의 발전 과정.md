# 운영체제의 발전

## 운영체제의 발전 과정

> 운영체제가 지난 수십 년 동안 어떻게 발전해왔는가?

<br/>

### 1. **순차처리(Serial Processing)**

> 1940년대 말에서 1950년대 중반, 컴퓨터가 처음 등장했을 때 컴퓨터를 사용했던 방법이다.

* 초창기 컴퓨터에서는, 운영체제라고 할 만한 것이 없었기에 사용자가 컴퓨터 하드웨어를 직접 다루는 방식으로 컴퓨터를 사용하였다. 
* 프로그래머가 기계어로 프로그램을 작성하면, 카드 판독기 같은 입력 장치에 프로그램을 적재하여 프로그램을 실행하는 방식이었다.

* 하지만, 순차처리 방식은 **스케줄링, 준비시간** 측면에서 매우 **비효율적**이라는 문제점이 존재하였다.

    * **스케줄링** : 순차처리 방식에서는 사용자는 컴퓨터를 사용하기 위해 예약을 해야 했다. 
    한 사용자가 30분 동안의 시간을 사용한다고 예약해 놓으면, 사용자는 30분동안 그 컴퓨터 전체를 그 시간동안 독점적으로 사용하였던 방식이었다. 
    그런데, 만약 30분 사용 예약을 하였는데 그보다 적은 시간 동안만 사용한다면 남은 시간동안 **컴퓨팅자원을 사용하지 않고 낭비**하게 된다.
    
    * **준비시간** : 또한 컴퓨터를 사용하기 위해 초기 셋업 작업이 선행되어야 하는데, 이 **준비 시간이 매우 오래 걸렸다**.

<br/>

### 2. **단순 일괄처리(배치) 시스템(Simple Batch System)**

> 순차처리 방식의 문제점을 해결하여 컴퓨터라는 (당시 기준으로) 비싼 기계를 효율적으로 사용하기 위해 1950년대 중반에 IBM 701용으로 처음 고안된 것이 최초의 운영체제인 **단순 일괄처리 시스템**이다.

* 구조 : 모니터라는 이름의 ‘소프트웨어’가 있고, 사용자 프로그램이 메모리에 적재되는 형태로 동작하는데, 모니터 부분이 지금의 운영체제 기능을 수행하는 곳이다. 

- 모니터라는 프로그램은 어떤 기능을 가지나?
인터럽트 처리, device drivers(장치관리), job sequencing(job: 컴퓨터가 처리해야 할 프로그램... 이 job들을 순차적으로 처리하는 기능), control language interpreter(컴퓨터에 어떤 명령을 주면, 그 명령어를 해석하여 컴퓨터에게 어떤 동작을 시키는 기능)

컴퓨터 시스템에다가 job을 신청(어떤 것을 하고 싶은지).... 천공 카드같은 것에 프로그램이나 데이터를 준비하여 operator에 전달
operator는 천공 카드를 차례대로 쌓아 컴퓨터에 집어넣음. 컴퓨터는 천공 카드를 읽어 처리. 그러니 중간에 순차처리처럼 컴퓨터가 중간에 사용되지 않는 시간이 사라지게 됨. 계속적으로 컴퓨터가 일을 처리할 수 있게 됨. 

- 유저프로그램에서는 어떻게 모니터에 접근하는가?
천공카드 기계, 프린터 등 외부장치가 있다고 하면, 모니터가 그 장치로부터 데이터를 읽어들이고, 다시 장치로 데이터를 출력하는(예를 들면 프린터기로) 일을 해야함.
여기에 필요한 모든 프로그램을 유저가 짤 필요가 없음. 이러한 프로그램이 모니터에 들어가 있음. 따라서 유저프로그램에서 프린팅을 하겠다고 모니터에게 기능을 요청하면, 모니터에 들어있는 프로그램이 장치를 제어해서 원하는 결과로 처리할 수 있도록 동작함.

모니터 프로그램이 위와 같은 일을 할 때/유저프로그램에서 어느 장치(프린터)를 이용하겠다고 하면, 그 시점에서 유저프로그램은 잠깐 ‘멈추고’, 모니터가 처리함. 그러다가 처리가 끝나면 ‘인터럽트’라는 것을 걸어 처리하는 기능을 함.
인터럽트를 처리하는 코드도 모니터에 들어있는 주요 모듈...

모니터는 메모리에 항상 있음. 모니터 프로그램은 굉장히 중요한 sw. 그렇기 때문에 유저프로그램이 모니터 프로그램 코드를 수정하려는 시도를 한다고 하면, 매우 위험할 수 있음. 그렇기 때문에, 모니터 영역을 보호할 수 있는 기능도 필요. 유저프로그램이 모니터 쪽을 접근하려고 하면, 유저프로그램의 수행을 정지시킴.

모니터 안에 있는 기계어/명령어들은 사용자 프로그램에서 돌아가는 기계어/명령어와는 다른 어떤 특별한 작업을 해야 할 수 있음. 이것을 previleged instruction(특권 명령어)라고 부름. 특권명령어를 실행해야 할 상황이 모니터 프로그램에서 있을 수 있음. 그렇기 때문에 컴퓨터 프로그램이 수행되는 상황의 모드를 두 가지 모드로 분류함.
하나는 user mode : 유저프로그램이 돌아가고 있는 상태의 모드
다른 하나는 kernal mode : 모니터 프로그램이 돌아가고 있는 모드
- 유저모드에서 사용자가 작성한 프로그램이 실행되다가, 모니터(커널)로 들어가면, 컴퓨터의 상태를 커널 모드로 바꿈. 그렇게 되면 특권명령어를 실행할 수 있게 됨. (유저모드에서는 특권명령어를 실행할 수 없도록 되어있음)

* 순차처리에서의 비효율적 사용을 극복하기 위해 단순 일괄처리 시스템을 고안하였지만, **레코드를 읽는데 걸리는 시간과 기계어/명령어를 읽는데 걸리는 시간에 차이가 존재함에 따라 시스템 사용률이 낮았다는 점에서** 여전히 비효율적이라는 문제점을 지녔다. 아래 내용은 그에 대한 예시이다.
 
    > 어떤 파일로부터 **레코드를 하나 읽어들이는 데 걸리는 시간이 15ms**인 반면, **명령어 100개를 실행하는 데에는 1ms가 걸리는 차이가** 존재한다고 가정한다. 다시 파일에 **한 개의 레코드를 저장하는 데 시간이 15ms**가 걸린다고 하면, 총 시간은 31ms가 걸릴 것이다.
    **31ms 중**, 파일을 읽거나 쓸 때는 처리기를 사용하지 않기 때문에 처리기를 사용하는 시간은 오직 **1ms**(명령어 실행)에 불과하다. 따라서 컴퓨터를 사용하는 전체 시간 중 1/31(**3.2%**) 만큼만 처리기를 이용한다는 결론에 이른다. 이렇게 **시스템 사용률이 낮다**는 점에서 여전히 비효율적인 방식이었다는 것이다.

<br/>

### 3. 멀티프로그램 일괄처리 시스템

어떻게 실행하는가?
단순일괄처리 시스템(a)에서는 어떤 프로그램A가 있으면 프로그램을 cpu사용하여 실행하던 중에 중간에 입출력이 생기면 기다림. 기다린 후에 다시 실행하는 방식으로 컴퓨터가 동작.
이러한 방식으로 하나의 job이 끝나면, 이어서 다음 job을 실행하는 형태

멀티프로그램 일괄처리 시스템(b)의 요지는 바로 이 대기하는 시간을 줄이자는 것. 어떻게? 다른 프로그램을 그 시간에 실행함으로써. 예를 들어 두 개의 프로그램(A, B)이 멀티프로그래밍 일괄처리 시스템에서는 프로그램 A가 실행되고 있을 때 I/O가 발생하면 프로그램 A는 기다려야 할 것. 그 동안에 B를 실행하자는 것. B가 실행되던 중 I/O가 발생하면 역시 기다림. I/O대기시간 중 A의 I/O가 끝날 것이고, 그 순간부터 다시 A프로그램이 다시 실행됨.
이런 식으로 하면, (a)의 경우보다 대기 시간이 줄고, 총 수행 시간이 짧아짐.(결합모습 보면)

이런 식으로 동작하기 위해서는 I/O가 시작되는 그 순간에 인터럽트를 걸어야 함. A프로그램 사용 중 I/O 발생한 순간 인터럽트가 걸리면 인터럽트에 의해 운영체제가 개입. 운영체제가 B를 실행시킴. I/O가 끝나면, I/O장치에서 인터럽트가 걸림. 운영체제에 인터럽트를 처리하는 부분이 있는데, 운영체제에서 다시 프로그램 A를 실행시켜줌. 이러한 방식이 멀티프로그램 시스템

세 개의 프로그램을 실행할 때도 마찬가지 원리... 대기시간이 획기적으로 줄어들음.

그러면 멀티프로그래밍의 효과는 무엇인가? p.6
그림을 보면 알 수 있듯이 단순일괄처리 시스템에서는 job1 프로그램이 실행이 끝나야 job2가 실행됨. job2번의 실행이 끝나야 job3이 실행됨. 이러한 형태로 동작
job1번은 보면, cpu와 메모리를 집중적으로 사용함. 연산이 굉장히 일어난다는 특징을 가지고 있다는 것을 알 수 있음. job2는 메모리, 터미널(단말기) 사용에 집중되어 있음. 타이핑을 많이 하는, 문서작성을 굉장히 많이 하는 프로그램임을 알 수 있음. 반면 job2에서 cpu는 적게 사용함. job3번은 메모리 약간 사용하고, 디스크와 프린터의 비중이 높음. 디스크에서 읽고, 프린터에서 출력하는 I/O작업이 매우 일어난다는 것을 알 수 있음.
-> 이렇듯, job별로 바쁜 부분과 널럴한 부분이 있다는 것을 알 수 있음. 또한 시간도 6칸으로 오래 걸림

반면, 멀티프로그래밍에서는 job 3개가 동시에 실행되다 보니, 그림에서 알 수 있듯 3칸으로 줄어들음. 놀고 있는 컴퓨팅 자원을 최소화... 사용되지 않는 시간을 최소화하였음. 더욱 컴퓨터를 효율적으로 사용할 수 있게 됨.

문제점 : p5의 그림(c)를 보면, 프로그램A에서 프로그램B로 넘어가기 위해서는 프로그램A 수행 도중에 I/O요구가 ‘걸려야’함. I/O요구가 있어야 비로소 A가 멈추고 프로그램 B가 실행될 수 있는 것. I/O 요구가 들어오는 시점은 불규칙할 것. 어떤 때는 A프로그램이 실행되는 시간이 길어, cpu를 처리하는 비중이 큰 시간이 오래 지속될 수 있음. A프로그램이 더 이상 cpu를 점유하지 않겠다고 제어를 내어주어야 다른 프로그램이 cpu를 사용할 수 있게 되는 형태로 동작. B프로그램 입장에서는 어떤 때는 이른 시점으로부터, 어떤 때는 늦은 시점으로부터 동작하게 될 수 있음.

4. 시분할시스템
3.의 문제를 극복하기 위해 시분할시스템이 개발됨.
job이 3개가 있다고 할 때, 시간을 1/n으로 쪼개어 할당된 시간만큼만 3개의 job이 시간을 점유할 수 있도록 하는 방법.
- 시간을 쪼개어, 각각의 시간 할당량만큼 각각의 프로그램이 시간을 점유하도록 동작하는 시스템

- 이 방식은 트랜잭션(컴퓨터와 사용자가 입출력을 주고받는) 처리에 적합하다.(은행같은 곳에서 응답시간을 빨리 하기 적합)
ex)ATM기에서 돈을 찾으려 할 때, ATM기는 즉시 사용자에 응답할 수 있어야 할 것임.
만약 멀티프로그래밍 방식으로 운영체제가 동작한다면, 먼저 cpu점유율이 높은 다른 프로그램을 가지고 작업하고 있는 쪽에서 오랫동안 프로그램을 사용하고 있다면, 멀티프로그램에서는 cpu를 점유하는 시간이 끝나야 내가 돈을 찾을 수가 있게 됨. 어떨 때는 ATM의 응답이 빠르고, 어떨 때는 ATM의 응답이 느릴 수 있음.

그래서 다른 영역에서 어떻게 사용하든지에 관계없이, 나에게 일정한 응답시간을 해주도록 하려면, 실행중인 각각의 프로그램의 시간을 잘게 쪼개어 배치함으로써 일정하면서도 짧은 시간 내에 실행할 기회가 주어질 것. 

1960년대에 만들어짐.
-당시 처음 만들어진 시스템 : CTSS
 ibm 709. 최대 32명까지 수용 가능
-오늘날 우리가 사용하는 운영체제가 바로 시분할 시스템임.

초기 시분할시스템의 모습
job1번(15000바이트. 남은 용량 12000바이트)이 처음에 메모리를 차지. -> 그러다 시간이 끝나고 다음으로 job2번(20000바이트 필요)이 실행되어야 함. 20000바이트가 필요한데, job1번을 버리고 job2번을 실행.(7000남음) -> 그 다음에, job3번은 5000바이트가 필요. job2번은 그대로 두고, job2 위에 job 3을 실행. -> job1다시 실행. job1은 15000바이트가 필요. 위에 15000바이트 차지. -> job4 실행. 그 위에 또 job4를 실행(job1, 2는 그대로 두기) -> job2실행되는데, 이미 5000만큼 job2가 수행중임. 그렇기 때문에 15000만큼만 메모리로 가져오면 된다.

결국 각 job이 실행될 때, 위에서부터 필요한 용량만큼 차지하고, 남은 부분은 그대로 둔다는 것... 
